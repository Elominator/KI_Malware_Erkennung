import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from collections import Counter
from MSIDataset import MSIDataset, list_files, load_sample, train_model
from LSTM_config import *

class LSTMClassifier(nn.Module):
    def __init__(self, input_dim=INPUT_DIM, hidden_dim=MODEL_DIM, num_layers=NUM_LAYERS, num_classes=NUM_CLASSES, chunk_size=CHUNK_SIZE, seq_len=FIXED_SEQ_LEN):
        super(LSTMClassifier, self).__init__()
        self.chunk_size = chunk_size
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.seq_len = seq_len

        self.embedding = nn.Linear(input_dim, hidden_dim)
        self.lstm = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)

        self.num_chunks = (seq_len + chunk_size - 1) // chunk_size

        self.fc1 = nn.Linear(self.num_chunks * hidden_dim, 64)
        self.bn1 = nn.BatchNorm1d(64)
        self.fc2 = nn.Linear(64, num_classes)
        
    def forward(self, x):
        batch_size, seq_len, _ = x.size()
        chunked_outputs = []

        for start in range(0, seq_len, self.chunk_size):
            end = min(start + self.chunk_size, seq_len)
            x_chunk = x[:, start:end, :]
            x_chunk = self.embedding(x_chunk)
            x_chunk, _ = self.lstm(x_chunk)
            chunked_outputs.append(torch.mean(x_chunk, dim=1))

        x = torch.cat(chunked_outputs, dim=1)

        x = self.fc1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return x

def main():
    global train_dataset, val_dataset

    encoded_files = list_files(ENCODED_DIR, '.exe.csv')
    classifications_files = list_files(CLASSIFICATIONS_DIR, '.exe.cifc')

    load_sample(encoded_files, classifications_files)

    dataset = MSIDataset(ENCODED_DIR, CLASSIFICATIONS_DIR, CHUNK_SIZE, FIXED_SEQ_LEN)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

    best_model = LSTMClassifier(input_dim=INPUT_DIM, 
                                hidden_dim=MODEL_DIM, 
                                num_layers=NUM_LAYERS,
                                num_classes=NUM_CLASSES,
                                chunk_size=CHUNK_SIZE,
                                seq_len=FIXED_SEQ_LEN)
    
    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    train_model(best_model, train_dataloader, val_dataloader, 
                learning_rate=LEARNING_RATE,
                weight_decay=WEIGHT_DECAY)

if __name__ == '__main__':
    main()
