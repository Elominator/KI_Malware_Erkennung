from torch.utils.data import Dataset, DataLoader, random_split
from config import *
import os
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import json
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import matplotlib.pyplot as plt

def list_files(directory, extension):
    """List files in a directory with a specific extension."""
    return sorted([f for f in os.listdir(directory) if f.endswith(extension)])


def load_sample(encoded_files, classifications_files):
    """Load and print a sample file for demonstration."""
    encoded_file_path = os.path.join(ENCODED_DIR, encoded_files[0])
    classification_file_path = os.path.join(CLASSIFICATIONS_DIR, classifications_files[0])

    df = pd.read_csv(encoded_file_path)
    try:
        with open(classification_file_path, 'r', encoding="utf-8") as f:
            classification = int(f.read().strip())
    except UnicodeDecodeError as e:
        print(f"Error decoding file: {e}")

    print("Sample Encoded Data Shape:", df.shape)
    print("Sample Classification:", classification)


def calculate_metrics(y_true, y_pred):
    """Calculate accuracy, precision, recall, and F1 score."""
    accuracy = accuracy_score(y_true, y_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')
    return accuracy, precision, recall, f1


def preprocess_data(data, input_dim):
    """Preprocess the data by normalizing and encoding."""
    df = pd.DataFrame(data, columns=[f'col{i+1}' for i in range(input_dim)])

    scaler = MinMaxScaler()
    df = df.astype(float)
    df.iloc[:, :-1] = scaler.fit_transform(df.iloc[:, :-1])


    if df[df.columns[-1]].nunique() < 5:
        df = pd.get_dummies(df, columns=[df.columns[-1]], prefix='category')
    else:
        df[df.columns[-1]] = scaler.fit_transform(df[[df.columns[-1]]])

    return df.values.astype(np.float32)


class MSIDataset(Dataset):
    def __init__(self, encoded_dir, classifications_dir, chunk_size, fixed_seq_len):
        """Initialize the dataset."""
        self.encoded_dir = encoded_dir
        self.classifications_dir = classifications_dir
        self.chunk_size = chunk_size
        self.fixed_seq_len = fixed_seq_len

        self.encoded_files = self._list_valid_files(encoded_dir, '.csv')
        self.classification_files = self._list_valid_files(classifications_dir, '.cifc')

        assert len(self.encoded_files) == len(self.classification_files), "Mismatched number of files"
    
    def __len__(self):
        return len(self.encoded_files)
    
    def __getitem__(self, idx):
        data, label = self._load_sample(idx)
        data = self._pad_or_truncate_sequence(data, self.fixed_seq_len)
        return torch.tensor(data, dtype=torch.float32), label, self.encoded_files[idx]

    def _list_valid_files(self, directory, extension):
        """List valid files in a directory with a specific extension."""
        return sorted([f for f in os.listdir(directory) if f.endswith(extension)])
    
    def _load_sample(self, idx):
        """Load a single sample."""
        encoded_path = os.path.join(self.encoded_dir, self.encoded_files[idx])
        classification_path = os.path.join(self.classifications_dir, self.classification_files[idx])
        
        df = pd.read_csv(encoded_path)
        data = preprocess_data(df.values, INPUT_DIM)
        with open(classification_path, encoding='utf-8') as f:
            label = int(f.read().strip())
        
        return data, label
    
    def _pad_or_truncate_sequence(self, data, fixed_seq_len):
        """Pad or truncate the sequence to a fixed length."""
        seq_len = data.shape[0]
        if seq_len > fixed_seq_len:
            return data[:fixed_seq_len, :]
        else:
            padding = np.zeros((fixed_seq_len - seq_len, data.shape[1]))
            return np.vstack([data, padding])

def initialize_weights(m):
    """Initialize weights with Kaiming Normal initialization."""
    if isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)


def load_json_data(file_path):
    """Load data from a JSON file."""
    with open(file_path, 'r') as f:
        return json.load(f)


def save_json_data(data, file_path):
    """Save data to a JSON file."""
    with open(file_path, 'w') as f:
        json.dump(data, f, indent=4)

def save_metrics(metrics, file_path=METRICS_FILE):
    """Save metrics to a JSON file."""
    with open(file_path, 'w') as f:
        json.dump(metrics, f, indent=4)


def load_metrics(file_path=METRICS_FILE, old=False):
    """Load metrics from a JSON file."""
    if os.path.exists(file_path) and old:
        with open(file_path, 'r') as f:
            return json.load(f)
    return {"epochs": [], "train_loss": [], "val_loss": [], "train_accuracy": [], "val_accuracy": [],
            "train_precision": [], "val_precision": [], "train_recall": [], "val_recall": [], 
            "train_f1": [], "val_f1": []}


def plot_metrics(metrics):
    """Plot the metrics."""
    epochs = metrics['epochs']

    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    plt.plot(epochs, metrics['train_loss'], label='Train Loss')
    plt.plot(epochs, metrics['val_loss'], label='Val Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Loss over Epochs')
    plt.legend()

    plt.subplot(2, 2, 2)
    plt.plot(epochs, metrics['train_accuracy'], label='Train Accuracy')
    plt.plot(epochs, metrics['val_accuracy'], label='Val Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Accuracy over Epochs')
    plt.legend()

    plt.subplot(2, 2, 3)
    plt.plot(epochs, metrics['train_precision'], label='Train Precision')
    plt.plot(epochs, metrics['val_precision'], label='Val Precision')
    plt.xlabel('Epochs')
    plt.ylabel('Precision')
    plt.title('Precision over Epochs')
    plt.legend()

    plt.subplot(2, 2, 4)
    plt.plot(epochs, metrics['train_recall'], label='Train Recall')
    plt.plot(epochs, metrics['val_recall'], label='Val Recall')
    plt.xlabel('Epochs')
    plt.ylabel('Recall')
    plt.title('Recall over Epochs')
    plt.legend()

    plt.tight_layout()
    plt.show()

def train_epoch(model, dataloader, learning_rate, weight_decay):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.train()
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    
    total_loss = 0
    correct = 0
    total = 0

    for batch_data, batch_labels, _ in dataloader:
        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)
        optimizer.zero_grad()
        
        outputs = model(batch_data)
        loss = criterion(outputs, batch_labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item() * batch_data.size(0)
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == batch_labels).sum().item()
        total += batch_labels.size(0)

    epoch_loss = total_loss / total
    epoch_accuracy = correct / total

    return epoch_loss, epoch_accuracy

def train_model(model, train_dataloader, val_dataloader, learning_rate, weight_decay, num_epochs=NUM_EPOCHS):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.apply(initialize_weights)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=PATIENCE, min_lr=MIN_LR)

    best_loss = float('inf')


    misclassified_samples = []
    low_confidence_samples = []

    metrics = load_metrics()

    for epoch in range(num_epochs):
        model.train()
        train_loss, train_correct, train_total = 0.0, 0, 0
        train_labels, train_preds = [], []
        
        for batch_data, batch_labels, filenames in train_dataloader:
            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)
            optimizer.zero_grad()
            
            outputs = model(batch_data)
            loss = criterion(outputs, batch_labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item() * batch_data.size(0)
            _, predicted = torch.max(outputs, 1)
            train_correct += (predicted == batch_labels).sum().item()
            train_total += batch_labels.size(0)
            
            train_labels.extend(batch_labels.cpu().numpy())
            train_preds.extend(predicted.cpu().numpy())

        
        train_loss /= train_total
        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(train_labels, train_preds)

        val_loss, val_accuracy, val_precision, val_recall, val_f1 = validate_model(model, val_dataloader, criterion, device)
        
        scheduler.step(val_loss)

        metrics['epochs'].append(epoch + 1)
        metrics['train_loss'].append(train_loss)
        metrics['val_loss'].append(val_loss)
        metrics['train_accuracy'].append(train_accuracy)
        metrics['val_accuracy'].append(val_accuracy)
        metrics['train_precision'].append(train_precision)
        metrics['val_precision'].append(val_precision)
        metrics['train_recall'].append(train_recall)
        metrics['val_recall'].append(val_recall)
        metrics['train_f1'].append(train_f1)
        metrics['val_f1'].append(val_f1)
        save_metrics(metrics)

        print(f'Epoch [{epoch+1}/{num_epochs}], '
              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '
              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')
        print(f'Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f}')
        print(f'Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}')

        if val_loss < best_loss:
            best_loss = val_loss
            torch.save(model.state_dict(), BEST_MODEL_FILE)
            print(f'Model saved with Val Loss: {best_loss:.4f}')

    save_json_data(misclassified_samples, MISCLASSIFIED_FILE)
    save_json_data(low_confidence_samples, LOW_CONFIDENCE_FILE)
    plot_metrics(metrics)


def validate_model(model, dataloader, criterion, device):
    """Validate the model."""
    model.eval()
    val_loss, val_correct, val_total = 0.0, 0, 0
    val_labels, val_preds = [], []
    
    with torch.no_grad():
        for batch_data, batch_labels, _ in dataloader:
            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)
            outputs = model(batch_data)
            loss = criterion(outputs, batch_labels)
            
            val_loss += loss.item() * batch_data.size(0)
            _, predicted = torch.max(outputs, 1)
            val_correct += (predicted == batch_labels).sum().item()
            val_total += batch_labels.size(0)
            
            val_labels.extend(batch_labels.cpu().numpy())
            val_preds.extend(predicted.cpu().numpy())
    
    val_loss /= val_total
    val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(val_labels, val_preds)
    return val_loss, val_accuracy, val_precision, val_recall, val_f1


def expand_samples(sample_data):
    """Expand the sample data to handle counts."""
    expanded_samples = {}
    for key, value in sample_data.items():
        expanded_samples[key] = {'count': value, 'details': {}}
    return expanded_samples

def update_misclassified(misclassified_samples, predicted, labels, filenames):
    """Update the misclassified samples."""
    for i in range(len(labels)):
        if predicted[i] != labels[i]:
            filename = filenames[i]
            if filename not in misclassified_samples:
                misclassified_samples[filename] = {'count': 0, 'details': {}}
            print(misclassified_samples[filename]['count'])
            misclassified_samples[filename]['count'] += 1
            label_str = str(labels[i].item())
            misclassified_samples[filename]['details'][label_str] = misclassified_samples[filename]['details'].get(label_str, 0) + 1


def update_low_confidence(low_confidence_samples, outputs, filenames, threshold=0.5):
    """Update the low confidence samples."""
    confidences, _ = torch.max(F.softmax(outputs, dim=1), 1)
    for i, confidence in enumerate(confidences):
        if confidence < threshold:
            filename = filenames[i]
            if filename not in low_confidence_samples:
                low_confidence_samples[filename] = {'count': 0, 'details': {}}
            low_confidence_samples[filename]['count'] = low_confidence_samples.get(filename, {'count': 0})['count'] + 1

